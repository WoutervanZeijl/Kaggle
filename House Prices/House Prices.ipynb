{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                           title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "------------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "shuofxz/titanic-machine-learning-from-disaster                Titanic: Machine Learning from Disaster            33KB  2017-10-15 10:05:34           8841        109  0.29411766       \n",
      "rashigoel/titanic-machine-learning-from-disaster              Titanic: Machine Learning from Disaster            34KB  2018-02-10 17:53:45           1544         19  0.29411766       \n",
      "harunshimanto/titanic-solution-a-beginners-guide              Titanic Solution: A Beginner's Guide               35KB  2018-03-11 14:23:57           1308         15  0.5294118        \n",
      "rahulsah06/titanic                                            Titanic                                            34KB  2019-09-16 14:43:23           8608        100  0.6764706        \n",
      "zain280/titanic-data-set                                      Titanic Data set                                   22KB  2024-02-28 14:04:13           2026         48  1.0              \n",
      "soylevbeytullah/titanic-datasets                              Titanic Datasets                                   34KB  2024-06-14 07:45:42             59          6  0.7058824        \n",
      "dwiuzila/titanic-machine-learning-from-disaster               Titanic - Machine Learning from Disaster           33KB  2021-04-27 03:08:44            351          3  0.3529412        \n",
      "ashishpatel26/titanicdisaster                                 Titanic: Machine Learning from Disaster            33KB  2018-03-21 10:44:07            347          1  0.29411766       \n",
      "whenamancodes/titanic-dataset-machine-learning-from-disaster  Titanic Dataset - Machine Learning from Disaster   34KB  2022-09-20 03:15:12            264          2  0.8235294        \n",
      "muhammadyasirsaleem/project                                   Titanic - Machine Learning from Disaster            9KB  2022-09-18 08:40:52             24          2  0.3529412        \n",
      "jankondracki/titanic-combined-dataset-with-relatiships        Titanic Dataset with Relationships                 35KB  2023-02-07 10:40:21            257         10  1.0              \n",
      "mpkanalytics/titanic-machine-learning-from-disaster           Titanic - Machine Learning from Disaster           33KB  2022-02-03 00:10:59             14          1  0.29411766       \n",
      "wesleyhowe/titanic-labelled-test-set                          Titanic - Labelled Test Set                        11KB  2023-05-30 13:52:23            130          4  0.9411765        \n",
      "damlapeker/titanicsurviveddatasets                            TitanicSurvivedDatasets                            22KB  2024-03-05 19:57:11            401         27  0.64705884       \n",
      "dreygaen/titanic-leaderboard                                  Titanic Leaderboard March 2023                    302KB  2023-03-31 22:11:54             49          3  1.0              \n",
      "krithikk/titanic-machine-learning-from-disaster               Titanic - Machine Learning from Disaster            2KB  2021-02-20 07:56:56             30          1  0.23529412       \n",
      "bayramyilmaztr/titanic-machine-learning-from-disaster         Titanic - Machine Learning from Disaster           22KB  2022-03-20 17:09:49             24          1  0.23529412       \n",
      "armourkai/titanic-machine-learning-from-disaster              Titanic - Machine Learning from Disaster           34KB  2021-09-30 03:41:09             12          1  0.23529412       \n",
      "kazihasib00/titanic-machine-learning-from-disaster            Titanic - Machine Learning from Disaster           34KB  2021-12-23 14:29:45             10          1  0.23529412       \n",
      "eyeseayou/titanic-machine-learning-from-disaster              Titanic - Machine Learning from Disaster           34KB  2022-04-25 02:36:06             11          1  0.23529412       \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list -s 'titanic - machine learning from disaster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Titanic.zip to /home/wouter/Desktop/Kaggle/Titanic\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 2.61MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Titanic.zip\n",
      "  inflating: data/gender_submission.csv  \n",
      "  inflating: data/test.csv           \n",
      "  inflating: data/train.csv          \n"
     ]
    }
   ],
   "source": [
    "!unzip Titanic.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm Titanic.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420382165605095"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women = train_data.loc[train_data['Sex'] == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "rate_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X,y)\n",
    "predicitons = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predicitons})\n",
    "output.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2.77k/2.77k [00:00<00:00, 7.12kB/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c Titanic -f submission.csv -m wouter_simple_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName        date                 description               status    publicScore  privateScore  \n",
      "--------------  -------------------  ------------------------  --------  -----------  ------------  \n",
      "submission.csv  2024-06-26 19:51:24  wouter_simple_submission  complete  0.77511                    \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
